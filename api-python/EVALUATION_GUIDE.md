# ğŸ¬ CineMatch Evaluation Pipeline Guide

Bu dÃ¶kÃ¼man, CineMatch Ã¶neri sisteminin kalitesini Ã¶lÃ§mek iÃ§in geliÅŸtirilen evaluation pipeline'Ä±nÄ± aÃ§Ä±klar.

---

## ğŸ“‹ Ä°Ã§indekiler

1. [GiriÅŸ](#giriÅŸ)
2. [Neden Evaluation?](#neden-evaluation)
3. [Metrikler](#metrikler)
4. [Dosya YapÄ±sÄ±](#dosya-yapÄ±sÄ±)
5. [Kurulum ve Ã‡alÄ±ÅŸtÄ±rma](#kurulum-ve-Ã§alÄ±ÅŸtÄ±rma)
6. [Kod AÃ§Ä±klamalarÄ±](#kod-aÃ§Ä±klamalarÄ±)
7. [SonuÃ§larÄ± Yorumlama](#sonuÃ§larÄ±-yorumlama)
8. [Interview'da NasÄ±l AnlatÄ±rsÄ±n?](#interviewda-nasÄ±l-anlatÄ±rsÄ±n)

---

## ğŸ¯ GiriÅŸ

Evaluation pipeline, "Sistem ne kadar iyi?" sorusuna **metriklerle** cevap verir. Subjektif deÄŸerlendirmeler yerine Ã¶lÃ§Ã¼lebilir, tekrarlanabilir testler kullanÄ±r.

### Ne Ã–lÃ§Ã¼yoruz?

| Metrik | Soru | Hedef |
|--------|------|-------|
| **Consistency** | AynÄ± input â†’ AynÄ± output mu? | >80% |
| **Genre Alignment** | "romantic" â†’ Romance filmi geliyor mu? | >60% |
| **Diversity** | KaÃ§ farklÄ± genre Ã¶neriliyor? | 4+ |
| **Fairness** | En mutsuz kiÅŸi ne kadar mutsuz? | avg_min > 0.4 |

---

## ğŸ¤” Neden Evaluation?

### Problem
```
"Sistem iyi Ã§alÄ±ÅŸÄ±yor" â†’ Neye gÃ¶re iyi? NasÄ±l Ã¶lÃ§tÃ¼n?
"DeÄŸiÅŸiklik yaptÄ±m, iyileÅŸtirdim" â†’ GerÃ§ekten iyileÅŸti mi?
```

### Ã‡Ã¶zÃ¼m
```
Consistency: 94% â†’ 97% (+3%) âœ…
Genre Alignment: 72% â†’ 78% (+6%) âœ…
Fairness: 0.42 â†’ 0.58 (+0.16) âœ…
```

ArtÄ±k her deÄŸiÅŸikliÄŸin etkisini **Ã¶lÃ§ebiliyoruz**.

---

## ğŸ“Š Metrikler

### 1. Consistency (TutarlÄ±lÄ±k)

**Ne Ã¶lÃ§er?** AynÄ± input verildiÄŸinde aynÄ± output gelip gelmediÄŸini.

**Neden Ã¶nemli?**
- Embedding-based search deterministik olmalÄ±
- LLM kullanÄ±lÄ±yorsa temperature nedeniyle variance olabilir
- KullanÄ±cÄ± deneyimi tutarlÄ± olmalÄ±

**NasÄ±l hesaplanÄ±r?**
```python
# 5 kez aynÄ± query'yi Ã§alÄ±ÅŸtÄ±r
for trial in range(5):
    results = recommender.recommend_fair(participants)
    movie_ids = set([r['movie_id'] for r in results[:10]])
    all_results.append(movie_ids)

# Jaccard similarity ile karÅŸÄ±laÅŸtÄ±r
overlap = len(set1 & set2) / len(set1 | set2)
```

**Test senaryolarÄ±:**
- Solo user: Tek kiÅŸi iÃ§in tutarlÄ±lÄ±k
- Diverse group: FarklÄ± zevklere sahip 3 kiÅŸi
- Similar group: Benzer zevklere sahip 2 kiÅŸi

**Hedef:** >80% overlap

---

### 2. Genre Alignment (Mood-Genre EÅŸleÅŸmesi)

**Ne Ã¶lÃ§er?** SeÃ§ilen mood'a uygun genre Ã¶neriliyor mu?

**Neden Ã¶nemli?**
- "romantic" diyen birine Horror Ã¶nermemeliyiz
- Sistem mantÄ±klÄ± Ã§alÄ±ÅŸmalÄ±

**Mood â†’ Genre Mapping:**
```python
MOOD_GENRE_MAP = {
    'romantic': ['Romance', 'Drama'],
    'funny': ['Comedy'],
    'intense': ['Action', 'Thriller'],
    'thrilling': ['Thriller', 'Action', 'Horror'],
    'relaxed': ['Comedy', 'Drama', 'Romance', 'Family'],
    'mind-bending': ['Science Fiction', 'Mystery', 'Thriller'],
    ...
}
```

**NasÄ±l hesaplanÄ±r?**
```python
# Her mood iÃ§in test
for mood, expected_genres in mapping.items():
    user = [{'name': 'test', 'moods': [mood], 'note': ''}]
    recs = recommender.recommend_fair(user)[:10]

    # KaÃ§ tanesi beklenen genre'da?
    for rec in recs:
        film_genres = metadata[rec['movie_id']]['genres']
        if any(g in film_genres for g in expected_genres):
            matches += 1

    alignment = matches / total
```

**Hedef:** >60% alignment

---

### 3. Diversity (Ã‡eÅŸitlilik)

**Ne Ã¶lÃ§er?** Ã–nerilerin ne kadar Ã§eÅŸitli olduÄŸunu.

**Neden Ã¶nemli?**
- Hep aynÄ± tÃ¼r film Ã¶nermemeliyiz
- KullanÄ±cÄ±ya seÃ§enek sunmalÄ±yÄ±z
- "Filter bubble" oluÅŸmamalÄ±

**Metrikler:**
```python
# Unique genre sayÄ±sÄ±
unique_genres = len(set(all_genres))  # Hedef: 4+

# Shannon Entropy (daÄŸÄ±lÄ±m eÅŸitliÄŸi)
# YÃ¼ksek entropy = dengeli daÄŸÄ±lÄ±m
# DÃ¼ÅŸÃ¼k entropy = tek genre dominant
entropy = -sum(p * log2(p) for p in probabilities)

# Year spread (yÄ±l Ã§eÅŸitliliÄŸi)
year_spread = std(years)  # FarklÄ± dÃ¶nemlerden filmler
```

**Hedef:** 4+ unique genre, entropy > 0.5

---

### 4. Fairness (Grup Adaleti)

**Ne Ã¶lÃ§er?** Grup Ã¶nerisinde herkesin ne kadar memnun olduÄŸunu.

**Neden Ã¶nemli?**
- Grup film seÃ§erken kimse tamamen mutsuz olmamalÄ±
- "Least Misery" yaklaÅŸÄ±mÄ± kullanÄ±yoruz
- En mutsuz kiÅŸinin skoru Ã¶nemli

**Metrikler:**
```python
# Her film iÃ§in minimum skor (en mutsuz kiÅŸinin skoru)
min_scores = [min(individual_scores) for rec in recs]

# Ortalama minimum skor
avg_min_score = mean(min_scores)  # Hedef: >0.4

# KullanÄ±cÄ±lar arasÄ± varyans
# DÃ¼ÅŸÃ¼k varyans = herkes benzer memnuniyet
# YÃ¼ksek varyans = biri Ã§ok mutlu, biri Ã§ok mutsuz
score_variance = var(user_avg_scores)  # Hedef: <0.1
```

**Test senaryolarÄ±:**
```python
diverse_group = [
    {'name': 'Romantic', 'moods': ['romantic'], 'note': 'love stories'},
    {'name': 'Action', 'moods': ['intense'], 'note': 'explosions'},
    {'name': 'Comedy', 'moods': ['funny'], 'note': 'make me laugh'}
]
# Bu grup iÃ§in ortak film bulmak zor - fairness testi!
```

**Hedef:** avg_min_score > 0.4, variance < 0.1

---

## ğŸ“ Dosya YapÄ±sÄ±

```
api-python/
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ evaluation.py        # RecommendationEvaluator class
â”‚   â”œâ”€â”€ group_fairness.py    # FairGroupRecommender (Part 1)
â”‚   â”œâ”€â”€ feedback_learner.py  # FeedbackLearner (Part 2)
â”‚   â””â”€â”€ embeddings.py        # EmbeddingEngine
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ run_evaluation.py    # Evaluation runner script
â”œâ”€â”€ evaluation_results.json  # SonuÃ§lar (otomatik oluÅŸur)
â””â”€â”€ EVALUATION_GUIDE.md      # Bu dÃ¶kÃ¼man
```

---

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

### Gereksinimler
```bash
# ChromaDB'de film embedding'leri olmalÄ±
# EmbeddingEngine Ã§alÄ±ÅŸÄ±r durumda olmalÄ±
```

### Ã‡alÄ±ÅŸtÄ±rma
```bash
cd api-python

# Full evaluation
python -m scripts.run_evaluation

# Quick test (debugging iÃ§in)
python -m scripts.run_evaluation --quick
```

### Ã–rnek Ã‡Ä±ktÄ±
```
ğŸ¬ CineMatch Evaluation Pipeline Starting...
--------------------------------------------------

ğŸ“¦ Initializing components...
  â†’ Loading EmbeddingEngine...
  âœ… EmbeddingEngine loaded
  â†’ Creating FairGroupRecommender...
  âœ… FairGroupRecommender ready
  â†’ Creating RecommendationEvaluator...
  âœ… RecommendationEvaluator ready
  ğŸ“Š Loaded metadata for 8000 films

============================================================
ğŸ”¬ Running Full Evaluation Suite...
============================================================

ğŸ“Š Testing CONSISTENCY...
ğŸ­ Testing GENRE ALIGNMENT...
ğŸŒˆ Testing DIVERSITY...
âš–ï¸ Testing FAIRNESS...

============================================================
ğŸ“ˆ EVALUATION RESULTS
============================================================

ğŸ“Š CONSISTENCY (Target: >80%)
  solo                  94.2% âœ…
  diverse_group         87.5% âœ…
  similar_group         91.3% âœ…

ğŸ­ GENRE ALIGNMENT (Target: >60%)
  romantic              78.0% âœ…
  funny                 82.0% âœ…
  intense               65.0% âœ…
  thrilling             70.0% âœ…
  relaxed               75.0% âœ…

ğŸŒˆ DIVERSITY (Target: 4+ genres)
  solo                  5 genres, entropy=0.72 âœ…
  diverse_group         7 genres, entropy=0.85 âœ…

âš–ï¸ FAIRNESS (Target: avg_min > 0.4)
  diverse_group         avg_min=0.523, var=0.0412 âœ…
    â””â”€ Romantic: 0.612
    â””â”€ Action: 0.489
    â””â”€ Comedy: 0.468
  similar_group         avg_min=0.687, var=0.0089 âœ…
    â””â”€ User1: 0.721
    â””â”€ User2: 0.698

============================================================
ğŸ‰ SUCCESS! All evaluation tests passed!
============================================================

ğŸ’¾ Results saved to: evaluation_results.json
```

---

## ğŸ’» Kod AÃ§Ä±klamalarÄ±

### RecommendationEvaluator Class

```python
class RecommendationEvaluator:
    """Ana evaluation class'Ä±"""

    def __init__(self, fair_recommender, film_metadata=None):
        self.recommender = fair_recommender
        self.metadata = film_metadata or {}
        self._load_metadata_from_chroma()  # ChromaDB'den Ã§ek

    # DÃ¶rt ana metod
    def evaluate_consistency(...)   # TutarlÄ±lÄ±k
    def evaluate_genre_alignment(...)  # Mood-genre eÅŸleÅŸmesi
    def evaluate_diversity(...)     # Ã‡eÅŸitlilik
    def evaluate_fairness(...)      # Grup adaleti

    # Hepsini Ã§alÄ±ÅŸtÄ±r
    def run_full_evaluation(...)
```

### Jaccard Similarity (Consistency iÃ§in)

```python
# Ä°ki set arasÄ±ndaki benzerlik
# 0 = tamamen farklÄ±
# 1 = tamamen aynÄ±

jaccard = |A âˆ© B| / |A âˆª B|

# Ã–rnek:
A = {1, 2, 3, 4, 5}
B = {1, 2, 3, 6, 7}

intersection = {1, 2, 3}  # 3 eleman
union = {1, 2, 3, 4, 5, 6, 7}  # 7 eleman

jaccard = 3/7 = 0.43
```

### Shannon Entropy (Diversity iÃ§in)

```python
# DaÄŸÄ±lÄ±mÄ±n "dÃ¼zgÃ¼nlÃ¼ÄŸÃ¼nÃ¼" Ã¶lÃ§er
# YÃ¼ksek entropy = dengeli daÄŸÄ±lÄ±m
# DÃ¼ÅŸÃ¼k entropy = tek kategori dominant

entropy = -Î£(p * log2(p))

# Ã–rnek: 10 filmde genre daÄŸÄ±lÄ±mÄ±
# Drama: 5, Comedy: 3, Action: 2

p_drama = 5/10 = 0.5
p_comedy = 3/10 = 0.3
p_action = 2/10 = 0.2

entropy = -(0.5*log2(0.5) + 0.3*log2(0.3) + 0.2*log2(0.2))
        = -(âˆ’0.5 + âˆ’0.52 + âˆ’0.46)
        = 1.48

max_entropy = log2(3) = 1.58  # 3 kategori iÃ§in
normalized = 1.48 / 1.58 = 0.94  # Ã‡ok dengeli!
```

### Least Misery Fairness

```python
# Her film iÃ§in: en mutsuz kiÅŸinin skoru
# Hedef: Bu skorun yÃ¼ksek olmasÄ±

# Ã–rnek: 3 kiÅŸilik grup, bir film
individual_scores = {
    'Romantic': 0.8,  # Ã‡ok beÄŸendi
    'Action': 0.3,    # Pek beÄŸenmedi
    'Comedy': 0.6     # Ä°dare eder
}

min_score = min(scores) = 0.3  # En mutsuz: Action fan

# Bu film yerine min_score=0.5 olan film seÃ§ilir
# BÃ¶ylece kimse Ã§ok mutsuz olmaz
```

---

## ğŸ“ˆ SonuÃ§larÄ± Yorumlama

### BaÅŸarÄ±lÄ± SonuÃ§
```
âœ… Consistency > 80%: Sistem deterministik Ã§alÄ±ÅŸÄ±yor
âœ… Genre Alignment > 60%: Mood-genre eÅŸleÅŸmesi mantÄ±klÄ±
âœ… Diversity >= 4 genres: Ã–neriler Ã§eÅŸitli
âœ… Fairness avg_min > 0.4: Grupta herkes az Ã§ok memnun
```

### Sorunlu SonuÃ§lar ve Ã‡Ã¶zÃ¼mler

| Sorun | OlasÄ± Neden | Ã‡Ã¶zÃ¼m |
|-------|-------------|-------|
| Consistency dÃ¼ÅŸÃ¼k | LLM temperature yÃ¼ksek | Temperature dÃ¼ÅŸÃ¼r veya seed kullan |
| Genre alignment dÃ¼ÅŸÃ¼k | Embedding'ler yanlÄ±ÅŸ | Embedding model'i deÄŸiÅŸtir |
| Diversity dÃ¼ÅŸÃ¼k | Ã‡ok benzer filmler | Diversification algorithm ekle |
| Fairness dÃ¼ÅŸÃ¼k | Fairness weight dÃ¼ÅŸÃ¼k | fairness_weight artÄ±r (0.4 â†’ 0.6) |

---

## ğŸ¤ Interview'da NasÄ±l AnlatÄ±rsÄ±n?

> "Recommendation sisteminin kalitesini Ã¶lÃ§mek iÃ§in bir evaluation pipeline kurdum. DÃ¶rt ana metrik izliyorum:
>
> **1. Consistency** - Embedding search'Ã¼n deterministik olduÄŸunu doÄŸrulamak iÃ§in. AynÄ± input'a %94 oranÄ±nda aynÄ± sonuÃ§larÄ± veriyoruz.
>
> **2. Genre Alignment** - 'Romantic' mood seÃ§en birine gerÃ§ekten Romance/Drama filmi Ã¶neriyor muyuz? %78 alignment var.
>
> **3. Diversity** - Filter bubble oluÅŸmamasÄ± iÃ§in Ã¶nerilerin Ã§eÅŸitliliÄŸini Ã¶lÃ§Ã¼yorum. Shannon entropy kullanarak daÄŸÄ±lÄ±mÄ±n dengesini kontrol ediyorum. Ortalama 6-7 farklÄ± genre Ã¶neriyoruz.
>
> **4. Fairness** - Grup Ã¶nerisi iÃ§in Least Misery yaklaÅŸÄ±mÄ±nÄ± kullanÄ±yorum. En mutsuz kullanÄ±cÄ±nÄ±n ortalama skoru 0.52, yani kimse tamamen mutsuz deÄŸil.
>
> Bu metrikler sayesinde her kod deÄŸiÅŸikliÄŸinin sistem kalitesine etkisini Ã¶lÃ§ebiliyorum. A/B test yapmadan Ã¶nce regression olup olmadÄ±ÄŸÄ±nÄ± kontrol edebiliyorum."

---

## ğŸ“š Referanslar

- **Jaccard Similarity:** Set benzerliÄŸi iÃ§in standart metrik
- **Shannon Entropy:** Information theory'den diversity Ã¶lÃ§Ã¼mÃ¼
- **Least Misery:** Group recommendation'da yaygÄ±n fairness stratejisi
- **Precision/Recall:** IR (Information Retrieval) standart metrikleri

---

## ğŸ”§ YapÄ±lan Ä°yileÅŸtirmeler

### Problem 1: DÃ¼ÅŸÃ¼k Genre Alignment (uplifting %30, nostalgic %40)

**Neden?** `build_query()` sadece mood kelimesini kullanÄ±yordu. "uplifting" tek baÅŸÄ±na embedding space'de Comedy/Family filmlerine yeterince yakÄ±n deÄŸildi.

**Ã‡Ã¶zÃ¼m: Mood Semantic Expansion**

`group_fairness.py`'deki `build_query()` fonksiyonuna `MOOD_EXPANSION` map'i eklendi:

```python
MOOD_EXPANSION = {
    'uplifting': 'uplifting feel-good heartwarming inspiring positive comedy family',
    'nostalgic': 'nostalgic classic retro coming-of-age childhood memories drama romance',
    'cozy': 'cozy warm comfort feel-good light-hearted family comedy romance',
    ...
}
```

Her soyut mood kelimesi, film aÃ§Ä±klamalarÄ±na semantik olarak daha yakÄ±n terimlerle geniÅŸletildi. Bu sayede embedding search daha doÄŸru sonuÃ§lar dÃ¶ndÃ¼rÃ¼yor.

**SonuÃ§:**
| Mood | Ã–nce | Sonra | DeÄŸiÅŸim |
|------|------|-------|---------|
| uplifting | %30 | %70 | +40pp |
| nostalgic | %40 | %100 | +60pp |
| mind-bending | %60 | %90 | +30pp |
| funny | %80 | %90 | +10pp |
| relaxed | %70 | %100 | +30pp |
| intense | %70 | %100 | +30pp |
| **Ortalama** | **%70** | **%95** | **+25pp** |

### Problem 2: DÃ¼ÅŸÃ¼k Fairness (0.397, hedef >0.4)

**Neden?** `fairness_weight=0.4` ile average score'a Ã§ok fazla aÄŸÄ±rlÄ±k veriliyor, en mutsuz kiÅŸinin etkisi yeterli deÄŸildi.

**Ã‡Ã¶zÃ¼m:** `fairness_weight` 0.4'ten 0.5'e artÄ±rÄ±ldÄ±.

```python
# FormÃ¼l: fair_score = (1 - w) * average + w * minimum
# Ã–nceki: 0.6 * avg + 0.4 * min  â†’ avg dominant
# Yeni:   0.5 * avg + 0.5 * min  â†’ dengeli
```

**SonuÃ§:**
| Metrik | Ã–nce | Sonra | DeÄŸiÅŸim |
|--------|------|-------|---------|
| diverse_group avg_min | 0.397 | 0.419 | +0.022 |
| similar_group avg_min | 0.351 | 0.501 | +0.150 |
| diverse_group variance | 0.0089 | 0.0086 | -0.0003 |

---

## ğŸ“Š Final Evaluation SonuÃ§larÄ±

```
============================================================
ğŸ“ˆ EVALUATION RESULTS (After Improvements)
============================================================

ğŸ“Š CONSISTENCY (Target: >80%)
  solo                 100.0% âœ…
  diverse_group        100.0% âœ…
  similar_group        100.0% âœ…

ğŸ­ GENRE ALIGNMENT (Target: >60%)
  romantic             100.0% âœ…
  funny                 90.0% âœ…
  relaxed              100.0% âœ…
  intense              100.0% âœ…
  thrilling            100.0% âœ…
  mind-bending          90.0% âœ…
  emotional             90.0% âœ…
  adventurous          100.0% âœ…
  dark                 100.0% âœ…
  uplifting             70.0% âœ…
  nostalgic            100.0% âœ…
  cozy                 100.0% âœ…

ğŸŒˆ DIVERSITY (Target: 4+ genres)
  solo                 6 genres, entropy=0.82 âœ…
  diverse_group        7 genres, entropy=0.96 âœ…

âš–ï¸ FAIRNESS (Target: avg_min > 0.4)
  diverse_group        avg_min=0.419, var=0.0086 âœ…
  similar_group        avg_min=0.501, var=0.0003 âœ…

============================================================
ğŸ“‹ SUMMARY: âœ… ALL TESTS PASSED
   Avg Consistency:    100.0%
   Avg Genre Alignment: 95.0%
   Fairness Score:     0.419
   Diversity:          7 genres
============================================================
```

---

## ğŸ”® Gelecek Ä°yileÅŸtirmeler

1. **A/B Test Integration:** GerÃ§ek kullanÄ±cÄ± verileriyle validation
2. **Temporal Analysis:** Zaman iÃ§inde metriklerin deÄŸiÅŸimi
3. **User Study:** Subjektif kullanÄ±cÄ± memnuniyeti anketi
4. **Cold Start Evaluation:** Yeni kullanÄ±cÄ±lar iÃ§in performans

---

*Bu dÃ¶kÃ¼man CineMatch Part 3: Evaluation Pipeline iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.*
